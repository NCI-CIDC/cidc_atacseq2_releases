#############################################################################################################
# pipeline_template
#
# This program is free software that contains third party software subject to various licenses, 
# namely, the GNU General Public License version 3 (or later), the GNU Affero General Public License 
# version 3 (or later), and the LaTeX Project Public License v.1.3(c). A list of the software contained 
# in this program, including the applicable licenses, can be accessed here: 
#
# You can redistribute and/or modify this program, including its components, only under the terms of 
# the applicable license(s).  
#
# This program is distributed in the hope that it will be useful, but "as is," WITHOUT ANY WARRANTY; 
# without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#
#
# Program:  Snakefile
# Version:  0.1
# Author:   Sami R. Cherikh, Travis L. Jensen
# Purpose:  Main snakefile for workflow template.
# Input:    Sample fastq files stored in a cloud location (google cloud, aws)
# Output:   'sample_metadata.csv','rseqc/bam_qc_parsed.tab', 'rseqc/bam_gc_parsed.tab'
#############################################################################################################

## Import modules
import shutil
import logging as _logging
import psutil
import os
from pathlib import Path
from box import Box
import yaml

wildcard_constraints:
    sample="[^_]+"


##############################
#       CONFIGURATION        #
##############################
## Specify YAML config file location
configfile: "preprocess_config.yaml"

## Directories
## source dir
SOURCEDIR     = config["srcdir"]
## pre-processing dir
PREDIR     = config["predir"]
## analysis data results dir
DATADIR       = config["datadir"]


#include: "./rules/common.smk"
def create_path_accessor(prefix: Path = Path(PREDIR)) -> Box:
    """Create a Box to provide '.' access to hierarchy of paths"""
    data = yaml.load(Path(config["file_layout"]).open(), Loader=yaml.SafeLoader)
    paths = {}
    for directory in data.keys():
        paths[directory] = {}
        for file_alias, file_name in data[directory].items():
            p = str(prefix / directory / file_name)
            paths[directory][file_alias] = str(p)
    return Box(paths, frozen_box=True)

## create file accessor
paths = create_path_accessor()


## Program names/locations
CLOUD        = config["cloud_prog"]
OPENSSL      = config["openssl_prog"]
CUTADAPT     = config["cutadapt_prog"]
TRIMMOMATIC  = config["trimmomatic_prog"]
FASTQC       = config["fastqc_prog"]
HISAT2        = config["hisat_prog"]
BWA        = config["bwa_prog"]
HISAT2BUILD   = HISAT2 + '-build'
HISAT2SPLICE  = HISAT2 + '_extract_splice_sites.py'
SAMTOOLS      = config["samtools_prog"]
FASTQDUMP    = config["fastqdump_prog"]
RSEQC         = config["rseqc_dir"]
MACS         = config["macs_prog"]



## Use the source dir to import helper modules
sys.path.append(SOURCEDIR+'/python')
import trimadapters
import getfile  
import putfile  
import utils 
import time

## Logging config
LOG_LEVEL = config["log_level"]
LOG_FILE  = config["log_file"]



##############################
#       SET GLOBAL VARS      #
##############################
## number of cores dedicated to run
NCORES  = int(config["ncores"])

## output sub folders
SUBDIRS  = config["subdirs"]

## Ensembl version number
ENSEMBL = config["ensembl_version"]

## Reference datasets
INDEXSEQ = 'genome/Homo_sapiens.ensembl.version'+str(ENSEMBL)+'.genome.fa'
ANNOTATIONS_GTF = 'annot/Homo_sapiens.ensembl.version'+str(ENSEMBL)+'.chr.gtf'

## Run fastqc?
RUN_FASTQC = int(config["run_fastqc"])

## Save intermediate files?
REMOVEINTFILES = not config["saveintlocalfiles"]

## List of samples to process
SAMID        = utils.toList(config["samid"]) 

## List of input files
FASTQ_1      = utils.toList(config["fastq1"])
FASTQ_2      = utils.toList(config["fastq2"])

## Adapter sequences
FP_ADAPTERS   = [x.strip() for x in utils.toList(config["fp_adapter_seq"])]
TP_ADAPTERS   = [x.strip() for x in utils.toList(config["tp_adapter_seq"])]

## Set single or paired end
if (FASTQ_2 != ['']):
    ENDS  = ['1','2']
else:
    ENDS  = ['1']

## Strandedness of experiment
STRANDED = int(config["stranded"])

## Determine whether adapters should be trimmed or not
TRIM_FP = sum([x == 'NA'  for x in FP_ADAPTERS]) == 0
TRIM_TP = sum([x == 'NA'  for x in TP_ADAPTERS]) == 0
TRIM_ADAPTERS_OUTPUT = '.fastq.gz' if (TRIM_FP or TRIM_TP) else '.skipped'

## Macs peak caller mode
PEAK_MODE = str(config["peak_mode"])

## Macs peak caller ext size for broad calls
EXTSIZE = str(config["ext_size"])

## Macs peak caller arbitrary shift in bp here
SHIFT = str(config["shift"])

## Macs min qvalue for sig peak
PEAK_FDR = str(config["peak_fdr"])

## Create peak mode str for macs
if len(ENDS)==1 and PEAK_MODE=='broad':
    PEAK_MODE_STR = '--broad --broad-cutoff %s --nomodel --shift %s --extsize %s' % (PEAK_FDR, SHIFT, EXTSIZE)
elif len(ENDS)==2 and PEAK_MODE=='broad':
    PEAK_MODE_STR = '--broad --broad-cutoff %s --nomodel --extsize %s' % (PEAK_FDR, EXTSIZE)
else:
    PEAK_MODE_STR = ''

## Configure uploading 
ARCHIVE = config["archive_bucket"]
DOARCHIVE = len(ARCHIVE) != 0

## Configure encryption
DOENCRYPT    = int(config["encrypt_local"]) == 1
DECRYPT_PASS = config["decrypt_pass"]
ENCRYPT_PASS = config["encrypt_pass"]

## Configure quality trimming level
QUAL_CUTOFF = config["quality_trim"]

## save unmapped reads or not
SAVEUNMAPPED = int(config["save_unmapped"]) == 1

## hash for encryption/decryption & Checksums
HASH = config["hash"]

## Set up logging to log file
_logging.basicConfig(level=LOG_LEVEL,
                    format='[cidc-atac] %(asctime)s - %(levelname)s - %(message)s',
                    datefmt='%m/%d/%Y %I:%M:%S %p',
                    handlers=[_logging.FileHandler(LOG_FILE)])



################################
#     DEFINE TARGET OUTPUT     #
################################

OUTPUT = [expand(paths.rseqc.bamqc_txt, sample=SAMID),
          expand(paths.rseqc.bamgc_txt, sample=SAMID),
          expand(paths.cnv.csv, sample=SAMID),
          expand(paths.peak.xls, sample=SAMID),
          expand(paths.chipqc.csv, sample=SAMID)]

if PEAK_MODE == "narrow":
    OUTPUT.append(expand(paths.motif.narrow_peak, sample=SAMID))
    OUTPUT.append(expand(paths.motif.summit, sample=SAMID))
else:
    OUTPUT.append(expand(paths.motif.broad_peak, sample=SAMID))
   
if RUN_FASTQC == 1:
    OUTPUT.append(expand(paths.fastqc.targz, sample=SAMID))



#########################################
#    Define any onstart or onsuccess    #
#########################################
onsuccess:
    ## Merge sample rseqc results into single result files
    merged_results = utils.mergeRSEQC(SOURCEDIR)

    ## Copy some results to analysis data dir
    [shutil.copy2(x, DATADIR) for x in merged_results]

    ## call ChIPQC on samples in mta and output results to analysis data dir - set last arg to one of the options [make-report, no-report]
    shell('Rscript --vanilla '+SOURCEDIR+'/r/init-chipqc-all-peak-metrics.r '+PREDIR+' '+DATADIR+' sample_metadata.csv make-report')

    ## add chipqc output to results to enc and archive if needed
    merged_results.append(['analysis/report/'+f for f in os.listdir('analysis/report')])
    merged_results.append('analysis/data/all_chipqc.csv.gz')

    ## Encrypt and/or upload main results if needed
    if DOENCRYPT:
        utils.encryptFile(file=merged_results, openssl=OPENSSL, password=ENCRYPT_PASS, hash=HASH)
        merged_results = [f+'.enc' for f in merged_results]
    if DOARCHIVE:
        [putfile.upload(file=x, destination=ARCHIVE, prog=CLOUD, doencrypt=DOENCRYPT) for x in merged_results]

    shell("echo 'Pipeline complete!'")



################################
#   PASS OUTPUT TO all RULE    #
################################
rule all:
    input:
        OUTPUT
    


################################
#        PIPELINE RULES        #
################################
include: "./rules/initialization.smk"
include: "./rules/ingest.smk"
include: "./rules/mapping.smk"
include: "./rules/analysis.smk"
include: "./rules/format_peaks.smk"
include: "./rules/motif.smk"
